{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SW 282: Lab 4 - Standard Deviation \n",
    "\n",
    "---\n",
    "\n",
    "### Professor Erin Kerrison\n",
    "\n",
    "In this lab, we consider the standard deviation and the data science technique of bootstrapping.\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Reading in SPSS FIles](#section-1)\n",
    "2. [Variance and Spread](#section-2)\n",
    "3. [Population Standard Deviation](#section-3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "\n",
    "To begin with the lab, run the cell below, which loads in all of the Python packages we'll be making use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading in SPSS Files <a id=\"section-1\"></a>\n",
    "\n",
    "While CSV is one of the more common formats for saving data, there are others as well (e.g. JSON, XML). The `datascience` library does not currently support reading in data formatted in this way, so instead we use a library called `pandas`, which is the industry standard for working with rectangular data.\n",
    "\n",
    "In this notebook, we will focus on how to import SPSS-formatted data (files with a `.sav` extension). This should prove particularly useful for folks who might have SPSS-formated datasets, but lack an active SPSS licence.  YAY for free and #OpenScience!!\n",
    "\n",
    "But I digress... We will use a library called `pyreadstat` which reads these SPSS (.sav) files into a pandas `DataFrame`, analogous to the `Table`s you've been working with thus far. Once we have the DataFrame, we can then use `Table.from_df()` from the `datascience` library to convert the DataFrame into a table for use.\n",
    "\n",
    "In the cell below, you will load in the data for this lab (the Reaction Time test mentioned in your Salkind reding) using `pyreadstat.read_sav()` and the `pyreadstat`-`pandas`-`datascience` pipeline discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = pyreadstat.read_sav(\"data/ch-3-ds-1.sav\")\n",
    "reaction_times = Table.from_df(df)\n",
    "reaction_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that are 200 observations in this univariate dataset. But what of their distribution??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variance and Spread <a id=\"section-2\"></a>\n",
    "\n",
    "In this section of the notebook, we will be looking at the _standard deviation_ of samples from our `reaction_time` data. The standard deviation is a measured of the _spread_ of a sample, and is defined as the root-mean-squared difference from the mean of the data.\n",
    "\n",
    "Let's consider the following question:\n",
    "\n",
    "> What is the standard deviation of the **population** (the larger group of interest) from which our sample is drawn?\n",
    "\n",
    "Generally, this question can't be answered exactly as we can't know the total population distribution from which our sampleis derived, but there are statistical techniques that we can use to attempt to answer such a question. One such technique is the **bootstrap**, in which we use data already collected to generate new samples in an attempt to estimate the value of a **population parameter** (or an estimated number that characterizes some attribute of the entire, but unknowable, poputlation). \n",
    "\n",
    "You may learn more about bootstrapping the future, but for our puposes here, we will focus on simply caluclating the distribution of a random tample taken from a larger population. In this notebook specifically, we will calucluate the standard deviation for a sample of scores taken from the `reaction_time` dataset that we read in just above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first take a look at our distribution by (1) generating a box plot of the \n",
    "# dataset, followed by (2) identifying several measures of central tnedency\n",
    "\n",
    "reaction_times.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "You can see that boxplots offer a fantastic summary of lies within what is considered \"normal\" for a given dataset's spread!! Here's rundown of what you're looking at (moving from the bottom of the graphic upwards): \n",
    "\n",
    "- The lowest, shortest horizontal line is the dataset's minimum value\n",
    "- The second, wider horizontal line is called the first quartile and indicates the 25% mark of the full distribution (24.99999 percent of the dataset's values are less than approximately 0.5 seconds, and the remaining values are greater than 0.5 seconds)\n",
    "- The red horizontal line represents the distriution's median value or 50th percentil mark (approximately 0.75 seconds)\n",
    "- The fourth horizontal  line represents the third quartile, or the 75% mark of the full distribution\n",
    "- The fifth and shortest horizontal line represents the maximum value that would allow hor a balnaced or normal distribution of the datset. \n",
    "- The four circles represent outliers, or values that are abnormal given the rest of the vales in the dataset and their spread. \n",
    "\n",
    "**QUESTION:** What does the boxplot you generated tell us about the spread of this univariate distribution (study participants' reported reaction times in this case)? What can you share about the distribution of the data? Please describe the dataset in the cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Type your answer here, replacing this text.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate one of the dataset's measures of central tendency. You will need to fill\n",
    "# in the command below by telling Python to caluclate the measures for our dataset \n",
    "# (please disregard the warning that might pop up upon running this code cell)\n",
    "\n",
    "np.mean(______)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**QUESTION:** Now that you've calculated the mean and you (more or less) know the median based on the what the box plot already illustrated, what can you say about the shape of this datasets distribution? What speciafically about the difference between the mean and the median makes you sure? Please provide your answers in the cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Type your answer here, replacing this text.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population Standard Deviation <a id=\"section-3\"></a>\n",
    "\n",
    "In the cell below, we will calculate the standard deviation of the `reaction_times` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to fill in the command below by telling Python to caluclate the measure\n",
    "# for our dataset (please disregard the warning that might pop up upon running this code cell)\n",
    "\n",
    "np.std(_______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**QUESTION:** Given what you now know about the distribution's mean, median, and standard devation, what can say about how particpants' reaction time scores were clustered? Answe the following two questions:\n",
    "- Would you expect to find a reaction time score of 2.21 seconds reported for this population?\n",
    "- Why or why not?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Type your answer here, replacing this text.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats on finishing another lab notebook! To turn in this lab assignment, go to File > Download as > PDF via Chrome and upload the PDF to bCourses.\n",
    "\n",
    "---\n",
    "Notebook developed by: Chris Pyles\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
